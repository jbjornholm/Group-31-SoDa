{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests,os,time\n",
    "def ratelimit():\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(0.5) # sleep one second.\n",
    "\n",
    "class Connector():\n",
    "  def __init__(self,logfile,overwrite_log=False,connector_type='requests',session=False,path2selenium='',n_tries = 5,timeout=30):\n",
    "    \"\"\"This Class implements a method for reliable connection to the internet and monitoring. \n",
    "    It handles simple errors due to connection problems, and logs a range of information for basic quality assessments\n",
    "    \n",
    "    Keyword arguments:\n",
    "    logfile -- path to the logfile\n",
    "    overwrite_log -- bool, defining if logfile should be cleared (rarely the case). \n",
    "    connector_type -- use the 'requests' module or the 'selenium'. Will have different since the selenium webdriver does not have a similar response object when using the get method, and monitoring the behavior cannot be automated in the same way.\n",
    "    session -- requests.session object. For defining custom headers and proxies.\n",
    "    path2selenium -- str, sets the path to the geckodriver needed when using selenium.\n",
    "    n_tries -- int, defines the number of retries the *get* method will try to avoid random connection errors.\n",
    "    timeout -- int, seconds the get request will wait for the server to respond, again to avoid connection errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Initialization function defining parameters. \n",
    "    self.n_tries = n_tries # For avoiding triviel error e.g. connection errors, this defines how many times it will retry.\n",
    "    self.timeout = timeout # Defining the maximum time to wait for a server to response.\n",
    "    ## not implemented here, if you use selenium.\n",
    "    if connector_type=='selenium':\n",
    "      assert path2selenium!='', \"You need to specify the path to you geckodriver if you want to use Selenium\"\n",
    "      from selenium import webdriver \n",
    "      ## HIN download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "      assert os.path.isfile(path2selenium),'You need to insert a valid path2selenium the path to your geckodriver. You can download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases'\n",
    "      self.browser = webdriver.Firefox(executable_path=path2selenium) # start the browser with a path to the geckodriver.\n",
    "\n",
    "    self.connector_type = connector_type # set the connector_type\n",
    "    \n",
    "    if session: # set the custom session\n",
    "      self.session = session\n",
    "    else:\n",
    "      self.session = requests.session()\n",
    "    self.logfilename = logfile # set the logfile path\n",
    "    ## define header for the logfile\n",
    "    header = ['id','project','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "    if os.path.isfile(logfile):        \n",
    "      if overwrite_log==True:\n",
    "        self.log = open(logfile,'w')\n",
    "        self.log.write(';'.join(header))\n",
    "      else:\n",
    "        self.log = open(logfile,'a')\n",
    "    else:\n",
    "      self.log = open(logfile,'w')\n",
    "      self.log.write(';'.join(header))\n",
    "    ## load log \n",
    "    with open(logfile,'r') as f: # open file\n",
    "        \n",
    "      l = f.read().split('\\n') # read and split file by newlines.\n",
    "      ## set id\n",
    "      if len(l)<=1:\n",
    "        self.id = 0\n",
    "      else:\n",
    "        self.id = int(l[-1][0])+1\n",
    "            \n",
    "  def get(self,url,project_name):\n",
    "    \"\"\"Method for connector reliably to the internet, with multiple tries and simple error handling, as well as default logging function.\n",
    "    Input url and the project name for the log (i.e. is it part of mapping the domain, or is it the part of the final stage in the data collection).\n",
    "    \n",
    "    Keyword arguments:\n",
    "    url -- str, url\n",
    "    project_name -- str, Name used for analyzing the log. Use case could be the 'Mapping of domain','Meta_data_collection','main data collection'. \n",
    "    \"\"\"\n",
    "     \n",
    "    project_name = project_name.replace(';','-') # make sure the default csv seperator is not in the project_name.\n",
    "    if self.connector_type=='requests': # Determine connector method.\n",
    "      for _ in range(self.n_tries): # for loop defining number of retries with the requests method.\n",
    "        ratelimit()\n",
    "        t = time.time()\n",
    "        try: # error handling \n",
    "          response = self.session.get(url,timeout = self.timeout) # make get call\n",
    "\n",
    "          err = '' # define python error variable as empty assumming success.\n",
    "          success = True # define success variable\n",
    "          redirect_url = response.url # log current url, after potential redirects \n",
    "          dt = t - time.time() # define delta-time waiting for the server and downloading content.\n",
    "          size = len(response.text) # define variable for size of html content of the response.\n",
    "          response_code = response.status_code # log status code.\n",
    "          ## log...\n",
    "          call_id = self.id # get current unique identifier for the call\n",
    "          self.id+=1 # increment call id\n",
    "          #['id','project_name','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row to be written in the log.\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write log.\n",
    "          self.log.flush()\n",
    "          return response,call_id # return response and unique identifier.\n",
    "\n",
    "        except Exception as e: # define error condition\n",
    "          err = str(e) # python error\n",
    "          response_code = '' # blank response code \n",
    "          success = False # call success = False\n",
    "          size = 0 # content is empty.\n",
    "          redirect_url = '' # redirect url empty \n",
    "          dt = t - time.time() # define delta t\n",
    "\n",
    "          ## log...\n",
    "          call_id = self.id # define unique identifier\n",
    "          self.id+=1 # increment call_id\n",
    "\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write row to log.\n",
    "          self.log.flush()\n",
    "    else:\n",
    "      t = time.time()\n",
    "      ratelimit()\n",
    "      self.browser.get(url) # use selenium get method\n",
    "      ## log\n",
    "      call_id = self.id # define unique identifier for the call. \n",
    "      self.id+=1 # increment the call_id\n",
    "      err = '' # blank error message\n",
    "      success = '' # success blank\n",
    "      redirect_url = self.browser.current_url # redirect url.\n",
    "      dt = t - time.time() # get time for get method ... NOTE: not necessarily the complete load time.\n",
    "      size = len(self.browser.page_source) # get size of content ... NOTE: not necessarily correct, since selenium works in the background, and could still be loading.\n",
    "      response_code = '' # empty response code.\n",
    "      row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row \n",
    "      self.log.write('\\n'+';'.join(map(str,row))) # write row to log file.\n",
    "      self.log.flush()\n",
    "    # Using selenium it will not return a response object, instead you should call the browser object of the connector.\n",
    "    ## connector.browser.page_source will give you the html.\n",
    "      return None,call_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = Connector('Cleaning')\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMLET\n",
    "gross=[]\n",
    "rating=[]\n",
    "movie_stars=[]\n",
    "director=[]\n",
    "year=[]\n",
    "name=[]\n",
    "genre=[]\n",
    "summary=[]\n",
    "\n",
    "for v in range (1,201):\n",
    "    url = 'https://www.imdb.com/search/keyword/?ref_=kw_ref_yr&mode=detail&page={}&title_type=movie&fbclid=IwAR3B7G9VdhKWjVvbFIPhdH9vGLZwmO_zzTeNlCj4whUMbn_RtS3g1g9FiUQ&release_date=1980%2C2019&sort=num_votes,desc'.format(v)\n",
    "    response,callid = connector.get(url,'Exam')\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    for j in range(50):\n",
    "        box=soup.findAll('div',{\"class\":'lister-item mode-detail'})[j]\n",
    "# BOX OFFICE\n",
    "        if len(box.findAll(\"span\", {\"name\": \"nv\"})) < 2:\n",
    "            gross.append(None)\n",
    "        if len(box.findAll(\"span\", {\"name\": \"nv\"})) == 2:\n",
    "            gross.append(box.findAll(\"span\", {\"name\": \"nv\"})[1].text)\n",
    "# Rating\n",
    "        if box.findAll(\"div\", {\"class\": \"inline-block ratings-imdb-rating\"})==[]:\n",
    "            rating.append(None)\n",
    "        else:\n",
    "            primo=box.findAll(\"div\", {\"class\": \"inline-block ratings-imdb-rating\"})[0].text\n",
    "            rating.append(primo.split('\\n')[2])\n",
    "# Movie Stars\n",
    "        if box.findAll(\"p\", {\"class\":\"text-muted text-small\"})== []:\n",
    "            movie_stars.append('NaN')\n",
    "        else: \n",
    "            stars = box.findAll(\"p\", {\"class\":\"text-muted text-small\"})[1].text.strip()\n",
    "            if len(stars.split(':'))<3:\n",
    "                movie_stars.append('NaN')\n",
    "            else:\n",
    "                stars_1 = stars.split(':')[2].split('\\n')[1:]\n",
    "                movie_stars.append(stars_1)\n",
    "# Directors\n",
    "        di=box.findAll(\"p\", {\"class\": \"text-muted text-small\"})[1].text\n",
    "        if len(di.split('Stars')[0].split('\\n')) > 5:\n",
    "            director.append(di.split('Stars')[0].split('\\n')[2:4])#+primo.split('Stars')[0].split('\\n')[3])\n",
    "        else:\n",
    "            director.append(di.split('Stars')[0].split('\\n')[2])\n",
    "# Years\n",
    "        headline_j = soup.findAll('h3')[j] # search for the first headline: h1 tag. \n",
    "        #name = headline_i['class'][0].strip() # use the class attribute name as column name.\n",
    "        value = headline_j.text.strip() # extract text using build in method        \n",
    "        film = value.split('\\n')[2]\n",
    "        if len(film)> 6:\n",
    "            film = value.split(' ')[-1]\n",
    "        year.append(film[1:5])\n",
    "# Name\n",
    "        headline_j = soup.findAll('h3')[j] # search for the first headline: h1 tag. \n",
    "        #name = headline_i['class'][0].strip() # use the class attribute name as column name.\n",
    "        value = headline_j.text.strip() # extract text using build in method.\n",
    "        film = value.split('\\n')[1]\n",
    "        name.append(film)\n",
    "# Genre\n",
    "        if box.findAll(\"span\", {\"class\":\"genre\"}) ==[]:\n",
    "            genre.append(None)\n",
    "        else: \n",
    "            movie_genre = box.findAll(\"span\", {\"class\":\"genre\"})[0].text.strip()\n",
    "            genre.append(movie_genre)\n",
    "# Summary\n",
    "        if box.findAll(\"p\", {\"class\":\"\"})== []:\n",
    "            summary.append(None)\n",
    "        else: \n",
    "            movie_summary = box.findAll(\"p\", {\"class\":\"\"})[0].text.strip()\n",
    "            summary.append(movie_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6a2916b81cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mStar_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_stars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mStar_1_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStar_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "Star_1_fn = []\n",
    "\n",
    "for i in range (10000): \n",
    "    Star_1 = movie_stars[i][0].strip().split(',')[0].split(' ')[0]\n",
    "    Star_1_fn.append(Star_1)  \n",
    "\n",
    "#for i in range (10000): \n",
    "#    Star_2 = movie_stars[i][1].strip().split(',')[0].split(' ')[0]\n",
    "#    Star_2_fn.append(Star_2)\n",
    "    \n",
    "#for i in range (10000): \n",
    "#    Star_3 = movie_stars[i][2].strip().split(',')[0].split(' ')[0]\n",
    "#    Star_3_fn.append(Star_3)\n",
    "    \n",
    "#for i in range (10000): \n",
    "#    Star_4 = movie_stars[i][3].strip().split(',')[0].split(' ')[0]\n",
    "#    Star_4_fn.append(Star_4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRABE FEMALE FIRST NAMES AND OTHERS\n",
    "first_female=[]\n",
    "sur_female=[]\n",
    "for i in range(1,8):\n",
    "    url='https://imdb.com/list/ls022928836/?sort=list_order,asc&mode=detail&page={}'.format(i)\n",
    "    call='Exam, KU, Female Page {}'.format(i)\n",
    "    response,call_id = connector.get(url, call)\n",
    "    html = response.text\n",
    "    soup=str(html)\n",
    "    if i < 7:\n",
    "        for i in range(1,101):\n",
    "            first_female.append((soup.split('div class=\"lister-list\"')[1].split('h3 class')[i].split('</span>\\n<a href=')[1].split('>')[1].split('\\n')[0].split(' ')[1]))\n",
    "            sur_female.append((soup.split('div class=\"lister-list\"')[1].split('h3 class')[i].split('</span>\\n<a href=')[1].split('>')[1].split('\\n')[0].split(' ')[2:]))\n",
    "    if i == 7:\n",
    "        for i in range(1,7):\n",
    "            first_female.append((soup.split('div class=\"lister-list\"')[1].split('h3 class')[i].split('</span>\\n<a href=')[1].split('>')[1].split('\\n')[0].split(' ')[1]))\n",
    "            sur_female.append((soup.split('div class=\"lister-list\"')[1].split('h3 class')[i].split('</span>\\n<a href=')[1].split('>')[1].split('\\n')[0].split(' ')[2:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natalie', 'Anne', 'Talia', 'Diane', 'Keira']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_female[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRABE MALE FIRST NAMES AND OTHERS\n",
    "first_male=[]\n",
    "sur_male=[]\n",
    "for i in range (1,8):\n",
    "    url='https://www.imdb.com/list/ls022928819/?sort=list_order,asc&mode=detail&page={}'.format(i)\n",
    "    call='Exam, KU, Male Page {}'.format(i)\n",
    "    response,call_id = connector.get(url, call)\n",
    "    html = response.text\n",
    "    soup=str(html)\n",
    "    if i < 7:\n",
    "        for i in range(1,101):\n",
    "            first_male.append((soup.split('div class=\"lister-list\"')[1].split('h3 class')[i].split('</span>\\n<a href=')[1].split('>')[1].split('\\n')[0].split(' ')[1]))\n",
    "            sur_male.append((soup.split('div class=\"lister-list\"')[1].split('h3 class')[i].split('</span>\\n<a href=')[1].split('>')[1].split('\\n')[0].split(' ')[2:]))\n",
    "    if i == 7:\n",
    "        for i in range(1,82):\n",
    "            first_male.append((soup.split('div class=\"lister-list\"')[1].split('h3 class')[i].split('</span>\\n<a href=')[1].split('>')[1].split('\\n')[0].split(' ')[1]))\n",
    "            sur_male.append((soup.split('div class=\"lister-list\"')[1].split('h3 class')[i].split('</span>\\n<a href=')[1].split('>')[1].split('\\n')[0].split(' ')[2:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Morgan', 'Leonardo', 'Brad', 'Michael', 'Robert']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_male[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329\n",
      "3049\n",
      "2943\n",
      "5425\n",
      "5127\n",
      "5001\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "name=nltk.corpus.names\n",
    "# CHECKING FOR OVERLAP IN THE ORIGINAL LIST\n",
    "name.fileids()\n",
    "name.words('male.txt') in name.words('female.txt')\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3\n",
    "check=intersection(first_female, name.words('female.txt'))\n",
    "# REMOVING DUPLICATES BY MAKING INTO DICT AND BACK AGAIN\n",
    "first_m=list(dict.fromkeys(first_male))\n",
    "first_f=list(dict.fromkeys(first_female))\n",
    "\n",
    "male_name=name.words('male.txt')+first_m\n",
    "print(len(male_name))\n",
    "first_m_done=list(dict.fromkeys(male_name))\n",
    "print(len(first_m_done))\n",
    "print(len(name.words('male.txt')))\n",
    "\n",
    "female_name=name.words('female.txt')+first_f\n",
    "print(len(female_name))\n",
    "first_f_done=list(dict.fromkeys(female_name))\n",
    "print(len(first_f_done))\n",
    "print(len(name.words('female.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_female = first_f_done\n",
    "all_male = first_m_done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_female,  file=open('all_female.txt', 'w'))\n",
    "print(all_male, file = open('all_male.txt','w'))\n",
    "print(Star_1_fn, file = open('Top Star first name', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
