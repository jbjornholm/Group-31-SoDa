{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,os,time\n",
    "def ratelimit():\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(1) # sleep one second.\n",
    "\n",
    "class Connector():\n",
    "  def __init__(self,logfile,overwrite_log=False,connector_type='requests',session=False,path2selenium='',n_tries = 5,timeout=30):\n",
    "    \"\"\"This Class implements a method for reliable connection to the internet and monitoring. \n",
    "    It handles simple errors due to connection problems, and logs a range of information for basic quality assessments\n",
    "    \n",
    "    Keyword arguments:\n",
    "    logfile -- path to the logfile\n",
    "    overwrite_log -- bool, defining if logfile should be cleared (rarely the case). \n",
    "    connector_type -- use the 'requests' module or the 'selenium'. Will have different since the selenium webdriver does not have a similar response object when using the get method, and monitoring the behavior cannot be automated in the same way.\n",
    "    session -- requests.session object. For defining custom headers and proxies.\n",
    "    path2selenium -- str, sets the path to the geckodriver needed when using selenium.\n",
    "    n_tries -- int, defines the number of retries the *get* method will try to avoid random connection errors.\n",
    "    timeout -- int, seconds the get request will wait for the server to respond, again to avoid connection errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Initialization function defining parameters. \n",
    "    self.n_tries = n_tries # For avoiding triviel error e.g. connection errors, this defines how many times it will retry.\n",
    "    self.timeout = timeout # Defining the maximum time to wait for a server to response.\n",
    "    ## not implemented here, if you use selenium.\n",
    "    if connector_type=='selenium':\n",
    "      assert path2selenium!='', \"You need to specify the path to you geckodriver if you want to use Selenium\"\n",
    "      from selenium import webdriver \n",
    "      ## HIN download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "      assert os.path.isfile(path2selenium),'You need to insert a valid path2selenium the path to your geckodriver. You can download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases'\n",
    "      self.browser = webdriver.Firefox(executable_path=path2selenium) # start the browser with a path to the geckodriver.\n",
    "\n",
    "    self.connector_type = connector_type # set the connector_type\n",
    "    \n",
    "    if session: # set the custom session\n",
    "      self.session = session\n",
    "    else:\n",
    "      self.session = requests.session()\n",
    "    self.logfilename = logfile # set the logfile path\n",
    "    ## define header for the logfile\n",
    "    header = ['id','project','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "    if os.path.isfile(logfile):        \n",
    "      if overwrite_log==True:\n",
    "        self.log = open(logfile,'w')\n",
    "        self.log.write(';'.join(header))\n",
    "      else:\n",
    "        self.log = open(logfile,'a')\n",
    "    else:\n",
    "      self.log = open(logfile,'w')\n",
    "      self.log.write(';'.join(header))\n",
    "    ## load log \n",
    "    with open(logfile,'r') as f: # open file\n",
    "        \n",
    "      l = f.read().split('\\n') # read and split file by newlines.\n",
    "      ## set id\n",
    "      if len(l)<=1:\n",
    "        self.id = 0\n",
    "      else:\n",
    "        self.id = int(l[-1][0])+1\n",
    "            \n",
    "  def get(self,url,project_name):\n",
    "    \"\"\"Method for connector reliably to the internet, with multiple tries and simple error handling, as well as default logging function.\n",
    "    Input url and the project name for the log (i.e. is it part of mapping the domain, or is it the part of the final stage in the data collection).\n",
    "    \n",
    "    Keyword arguments:\n",
    "    url -- str, url\n",
    "    project_name -- str, Name used for analyzing the log. Use case could be the 'Mapping of domain','Meta_data_collection','main data collection'. \n",
    "    \"\"\"\n",
    "     \n",
    "    project_name = project_name.replace(';','-') # make sure the default csv seperator is not in the project_name.\n",
    "    if self.connector_type=='requests': # Determine connector method.\n",
    "      for _ in range(self.n_tries): # for loop defining number of retries with the requests method.\n",
    "        ratelimit()\n",
    "        t = time.time()\n",
    "        try: # error handling \n",
    "          response = self.session.get(url,timeout = self.timeout) # make get call\n",
    "\n",
    "          err = '' # define python error variable as empty assumming success.\n",
    "          success = True # define success variable\n",
    "          redirect_url = response.url # log current url, after potential redirects \n",
    "          dt = t - time.time() # define delta-time waiting for the server and downloading content.\n",
    "          size = len(response.text) # define variable for size of html content of the response.\n",
    "          response_code = response.status_code # log status code.\n",
    "          ## log...\n",
    "          call_id = self.id # get current unique identifier for the call\n",
    "          self.id+=1 # increment call id\n",
    "          #['id','project_name','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row to be written in the log.\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write log.\n",
    "          return response,call_id # return response and unique identifier.\n",
    "\n",
    "        except Exception as e: # define error condition\n",
    "          err = str(e) # python error\n",
    "          response_code = '' # blank response code \n",
    "          success = False # call success = False\n",
    "          size = 0 # content is empty.\n",
    "          redirect_url = '' # redirect url empty \n",
    "          dt = t - time.time() # define delta t\n",
    "\n",
    "          ## log...\n",
    "          call_id = self.id # define unique identifier\n",
    "          self.id+=1 # increment call_id\n",
    "\n",
    "          row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row\n",
    "          self.log.write('\\n'+';'.join(map(str,row))) # write row to log.\n",
    "    else:\n",
    "      t = time.time()\n",
    "      ratelimit()\n",
    "      self.browser.get(url) # use selenium get method\n",
    "      ## log\n",
    "      call_id = self.id # define unique identifier for the call. \n",
    "      self.id+=1 # increment the call_id\n",
    "      err = '' # blank error message\n",
    "      success = '' # success blank\n",
    "      redirect_url = self.browser.current_url # redirect url.\n",
    "      dt = t - time.time() # get time for get method ... NOTE: not necessarily the complete load time.\n",
    "      size = len(self.browser.page_source) # get size of content ... NOTE: not necessarily correct, since selenium works in the background, and could still be loading.\n",
    "      response_code = '' # empty response code.\n",
    "      row = [call_id,project_name,self.connector_type,t,dt,url,redirect_url,size,response_code,success,err] # define row \n",
    "      self.log.write('\\n'+';'.join(map(str,row))) # write row to log file.\n",
    "    # Using selenium it will not return a response object, instead you should call the browser object of the connector.\n",
    "    ## connector.browser.page_source will give you the html.\n",
    "      return call_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = 'name_list'## name your log file.\n",
    "connector = Connector(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/list/ls022928836/'\n",
    "response,call_id = connector.get(url,'finding_actress_names')\n",
    "if response.ok:\n",
    "    html = response.text\n",
    "else:\n",
    "    print('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#links = set()\n",
    "\n",
    "#for link_loc in html.split('href=\"')[1:]:\n",
    "#    link = link_loc.split('\"')[0]\n",
    "#    if '/names/' in link:\n",
    "#        links.add(link)\n",
    "\n",
    "\n",
    "#html.split('href=\"')[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor and actress names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(html,'html.parser')\n",
    "\n",
    "male_name = []\n",
    "for i in range(1,8): \n",
    "    url = 'https://www.imdb.com/list/ls022928819/?sort=list_order,asc&mode=detail&page={}'.format(i)\n",
    "    call = 'Exam, KU{}'.format(i)\n",
    "    response,call_id = connector.get(url, call)\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "    else:\n",
    "        print('error')\n",
    "    soup= BeautifulSoup(html,'html.parser')\n",
    "    if i < 7:\n",
    "        for j in range(0,100): \n",
    "            tree_node = soup.findAll('h3')[j]\n",
    "            name = tree_node.text.split('\\n')[2].strip()\n",
    "            male_name.append(name)\n",
    "    else :\n",
    "        for j in range(0,81): \n",
    "            tree_node = soup.findAll('h3')[j]\n",
    "            name = tree_node.text.split('\\n')[2].strip()\n",
    "            male_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_name = []\n",
    "for i in range(1,8): \n",
    "    url = 'https://www.imdb.com/list/ls022928836/?sort=list_order,asc&mode=detail&page={}'.format(i)\n",
    "    call = 'Exam, KU{}'.format(i)\n",
    "    response,call_id = connector.get(url, call)\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "    else:\n",
    "        print('error')\n",
    "    soup= BeautifulSoup(html,'html.parser')\n",
    "    if i < 7:\n",
    "        for j in range(0,100): \n",
    "            tree_node = soup.findAll('h3')[j]\n",
    "            name = tree_node.text.split('\\n')[2].strip()\n",
    "            female_name.append(name)\n",
    "    else :\n",
    "        for j in range(0,6): \n",
    "            tree_node = soup.findAll('h3')[j]\n",
    "            name = tree_node.text.split('\\n')[2].strip()\n",
    "            female_name.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genre= []\n",
    "movie_summary = []\n",
    "movie_stars = []\n",
    "\n",
    "for v in range(1,201):\n",
    "    url1 = 'https://www.imdb.com/search/keyword/?ref_=kw_ref_yr&mode=detail&page={}&title_type=movie&fbclid=IwAR3B7G9VdhKWjVvbFIPhdH9vGLZwmO_zzTeNlCj4whUMbn_RtS3g1g9FiUQ&release_date=1980%2C2019&sort=num_votes,desc'.format(v)\n",
    "    call = 'Exam, KU{}'.format(v)\n",
    "    response,callid = connector.get(url1, call)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    \n",
    "    for j in range(50):\n",
    "        if soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"span\", {\"class\":\"genre\"}) ==[]:\n",
    "            movie_genre.append(None)\n",
    "        else: \n",
    "            genre = soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"span\", {\"class\":\"genre\"})[0].text.strip()\n",
    "            movie_genre.append(genre)\n",
    "        if soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"\"})== []:\n",
    "            movie_summary.append(None)\n",
    "        else: \n",
    "            summary = soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"\"})[0].text.strip()\n",
    "            movie_summary.append(summary)\n",
    "        if soup.findAll('div',{\"class\":'lister-item mode-detail'})[0].findAll(\"p\", {\"class\":\"text-muted text-small\"})== []:\n",
    "            movie_stars.append(None)\n",
    "        else: \n",
    "            stars = soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"text-muted text-small\"})[1].text.strip()\n",
    "            stars_1 = stars.split('Stars')[1].split('\\n')[1:5]\n",
    "            movie_stars.append(stars_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(movie_genre))\n",
    "print(len(movie_summary))\n",
    "print(len(movie_stars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_summary = []\n",
    "\n",
    "for v in range(1, 3):\n",
    "    url1 = 'https://www.imdb.com/search/keyword/?ref_=kw_ref_typ&sort=moviemeter%2Casc&mode=detail&page={}&title_type=movie&fbclid=IwAR3AAeVD_whYi1AwPsSGdYsgH8FnupVrBhImRFD__GL3wdHegJwcxrUsfyc'.format(v)\n",
    "    call = 'Exam, KU{}'.format(v)\n",
    "    response,callid = connector.get(url1, call)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    for j in range(0, 50): \n",
    "        if soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"\"})== []:\n",
    "            movie_summary.append(None)\n",
    "        else: \n",
    "            summary = soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"\"})[0].text.strip()\n",
    "            movie_summary.append(summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A faded television actor and his stunt double strive to achieve fame and success in the film industry during the final years of Hollywood's Golden Age in 1969 Los Angeles.\""
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(movie_summary))\n",
    "movie_summary[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_director = []\n",
    "\n",
    "for v in range(1, 3):\n",
    "    url1 = 'https://www.imdb.com/search/keyword/?ref_=kw_ref_typ&sort=moviemeter%2Casc&mode=detail&page={}&title_type=movie&fbclid=IwAR3AAeVD_whYi1AwPsSGdYsgH8FnupVrBhImRFD__GL3wdHegJwcxrUsfyc'.format(v)\n",
    "    call = 'Exam, KU{}'.format(v)\n",
    "    response,callid = connector.get(url1, call)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    for j in range(0, 50): \n",
    "        if soup.findAll('div',{\"class\":'lister-item mode-detail'})[0].findAll(\"p\", {\"class\":\"text-muted text-small\"})== []:\n",
    "            movie_director.append(None)\n",
    "        else: \n",
    "            director = soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"text-muted text-small\"})[1].text.strip()\n",
    "            director_1 = director.split('Stars')[0].split('\\n')[1]\n",
    "            movie_director.append(director_1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_director)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding movie stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stars = []\n",
    "\n",
    "for v in range(1, 3):\n",
    "    url1 = 'https://www.imdb.com/search/keyword/?ref_=kw_ref_typ&sort=moviemeter%2Casc&mode=detail&page={}&title_type=movie&fbclid=IwAR3AAeVD_whYi1AwPsSGdYsgH8FnupVrBhImRFD__GL3wdHegJwcxrUsfyc'.format(v)\n",
    "    call = 'Exam, KU{}'.format(v)\n",
    "    response,callid = connector.get(url1, call)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    for j in range(0, 50): \n",
    "        if soup.findAll('div',{\"class\":'lister-item mode-detail'})[0].findAll(\"p\", {\"class\":\"text-muted text-small\"})== []:\n",
    "            movie_stars.append(None)\n",
    "        else: \n",
    "            stars = soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"text-muted text-small\"})[1].text.strip()\n",
    "            stars_1 = stars.split('Stars')[1].split('\\n')[1:5]\n",
    "            movie_stars.append(stars_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding everything at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-74809babf8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0murl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.imdb.com/search/keyword/?ref_=kw_ref_yr&mode=detail&page={}&title_type=movie&fbclid=IwAR3B7G9VdhKWjVvbFIPhdH9vGLZwmO_zzTeNlCj4whUMbn_RtS3g1g9FiUQ&release_date=1980%2C2019&sort=num_votes,desc'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Exam, KU{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "movie_genre= []\n",
    "movie_summary = []\n",
    "movie_stars = []\n",
    "\n",
    "for v in range(1,201):\n",
    "    url1 = 'https://www.imdb.com/search/keyword/?ref_=kw_ref_yr&mode=detail&page={}&title_type=movie&fbclid=IwAR3B7G9VdhKWjVvbFIPhdH9vGLZwmO_zzTeNlCj4whUMbn_RtS3g1g9FiUQ&release_date=1980%2C2019&sort=num_votes,desc'.format(v)\n",
    "    call = 'Exam, KU{}'.format(v)\n",
    "    response,callid = connector.get(url1, call)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    print(v)\n",
    "    for j in range(50):\n",
    "        if soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"span\", {\"class\":\"genre\"}) ==[]:\n",
    "            movie_genre.append(None)\n",
    "        else: \n",
    "            genre = soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"span\", {\"class\":\"genre\"})[0].text.strip()\n",
    "            movie_genre.append(genre)\n",
    "        if soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"\"})== []:\n",
    "            movie_summary.append(None)\n",
    "        else: \n",
    "            summary = soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"\"})[0].text.strip()\n",
    "            movie_summary.append(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(movie_genre))\n",
    "print(len(movie_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if soup.findAll('div',{\"class\":'lister-item mode-detail'})[0].findAll(\"p\", {\"class\":\"text-muted text-small\"})== []:\n",
    "            movie_stars.append(None)\n",
    "        else: \n",
    "            stars = soup.findAll('div',{\"class\":'lister-item mode-detail'})[j].findAll(\"p\", {\"class\":\"text-muted text-small\"})[1].text.strip()\n",
    "            stars_1 = stars.split('Stars')[1].split('\\n')[1:5]\n",
    "            movie_stars.append(stars_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
