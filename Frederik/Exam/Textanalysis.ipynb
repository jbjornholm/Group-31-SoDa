{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import requests\n",
    "import nltk, nltk.sentiment, sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "name=nltk.corpus.names\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "vader=nltk.sentiment.vader.SentimentIntensityAnalyzer()\n",
    "from afinn import Afinn\n",
    "afinn = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female</th>\n",
       "      <th>d_Female</th>\n",
       "      <th>Summary</th>\n",
       "      <th>d_Drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>When the menace known as The Joker emerges fro...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A thief who steals corporate secrets through t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>An insomniac office worker and a devil-may-car...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The lives of two mob hitmen, a boxer, a gangst...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A bullied teenage boy is devastated after the ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A psychiatrist tries to put her life back toge...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A man who was abducted by aliens returns to hi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A psychiatrist makes multiple trips through ti...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A twenty-nine year-old slacker who lives with ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8264 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Female  d_Female                                            Summary  \\\n",
       "0        0.0       0.0  Two imprisoned men bond over a number of years...   \n",
       "1        0.0       0.0  When the menace known as The Joker emerges fro...   \n",
       "2        0.0       0.0  A thief who steals corporate secrets through t...   \n",
       "3        0.0       0.0  An insomniac office worker and a devil-may-car...   \n",
       "4        0.0       0.0  The lives of two mob hitmen, a boxer, a gangst...   \n",
       "...      ...       ...                                                ...   \n",
       "8259     0.0       0.0  A bullied teenage boy is devastated after the ...   \n",
       "8260     0.0       0.0  A psychiatrist tries to put her life back toge...   \n",
       "8261     0.0       0.0  A man who was abducted by aliens returns to hi...   \n",
       "8262     0.0       0.0  A psychiatrist makes multiple trips through ti...   \n",
       "8263     1.0       0.0  A twenty-nine year-old slacker who lives with ...   \n",
       "\n",
       "      d_Drop  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "8259     0.0  \n",
       "8260     1.0  \n",
       "8261     0.0  \n",
       "8262     0.0  \n",
       "8263     0.0  \n",
       "\n",
       "[8264 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2data='C:/Users/frede/OneDrive/Documents/GitHub/Group/Group-31-SoDa/Data/movie_1.csv'\n",
    "done=pd.read_csv(path2data)\n",
    "text=done[['Female','d_Female','Summary','d_Drop']]\n",
    "text.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "bob=text['Summary'].apply(vader.polarity_scores)\n",
    "bob_2=list(bob)\n",
    "text[[\"vader_neg\",\"vader_neu\",\"vader_pos\",\"vader_compound\"]]=pd.DataFrame(bob_2)\n",
    "text['Afinn']=text['Summary'].apply(afinn.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 27 samples and 32 outcomes>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 3),\n",
       " (',', 2),\n",
       " ('his', 2),\n",
       " ('to', 2),\n",
       " ('based', 1),\n",
       " ('on', 1),\n",
       " ('true', 1),\n",
       " ('story', 1),\n",
       " ('of', 1),\n",
       " ('jordan', 1)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "def preprocessing(string):\n",
    "    lower=string.lower()\n",
    "    token=tokenizer.tokenize(lower)\n",
    "    return token\n",
    "text['Token']=text['Summary'].apply(preprocessing)\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(text['Token'][25])\n",
    "print(fdist)\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19827 samples and 110796 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 6823),\n",
       " ('.', 4412),\n",
       " ('a', 2356),\n",
       " ('young', 628),\n",
       " ('man', 596),\n",
       " ('life', 531),\n",
       " ('new', 529),\n",
       " ('\"', 484),\n",
       " ('-', 419),\n",
       " ('one', 376),\n",
       " ('must', 369),\n",
       " ('find', 365),\n",
       " ('family', 363),\n",
       " ('world', 308),\n",
       " ('two', 307),\n",
       " ('story', 299),\n",
       " ('love', 287),\n",
       " ('the', 273),\n",
       " ('finds', 273),\n",
       " ('woman', 261),\n",
       " ('group', 257),\n",
       " ('see', 250),\n",
       " ('...', 248),\n",
       " (\"'\", 245),\n",
       " ('friends', 235),\n",
       " ('full', 235),\n",
       " ('(', 229),\n",
       " (')', 224),\n",
       " ('war', 215),\n",
       " ('summary', 214),\n",
       " ('»', 214),\n",
       " ('father', 213),\n",
       " ('help', 211),\n",
       " ('school', 211),\n",
       " ('get', 204),\n",
       " ('becomes', 202),\n",
       " ('years', 199),\n",
       " ('wife', 194),\n",
       " ('back', 193),\n",
       " ('city', 192)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "text_m=text[text.Female != 1].reset_index()\n",
    "stop=stopwords.words('english')\n",
    "stop1=stop+list(','+'a'+'.'+'\"')\n",
    "def remove_stop(x):\n",
    "    removed_stop=[]\n",
    "    for y in x:\n",
    "        removed_stop.append(' '.join([word for word in y.split() if word not in stop1]))\n",
    "    return removed_stop\n",
    "no_stop_m=remove_stop(text_m['Summary'])\n",
    "\n",
    "su_m=str()\n",
    "for i in range(6184):\n",
    "    su_m=su_m + str(no_stop_m[i])\n",
    "\n",
    "su_m_1=preprocessing(su_m)\n",
    "\n",
    "fdist = FreqDist(su_m_1)\n",
    "print(fdist)\n",
    "fdist.most_common(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6098 samples and 17633 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 1198),\n",
       " ('.', 703),\n",
       " ('a', 416),\n",
       " ('woman', 154),\n",
       " ('young', 153),\n",
       " ('new', 108),\n",
       " ('life', 98),\n",
       " ('girl', 78),\n",
       " ('one', 72),\n",
       " ('love', 69),\n",
       " ('-', 66),\n",
       " ('finds', 62),\n",
       " ('family', 59),\n",
       " ('must', 57),\n",
       " ('school', 55),\n",
       " ('man', 54),\n",
       " ('group', 54),\n",
       " ('mother', 53),\n",
       " ('\"', 50),\n",
       " ('world', 46),\n",
       " ('home', 44),\n",
       " ('two', 42),\n",
       " ('story', 42),\n",
       " ('friends', 41),\n",
       " ('mysterious', 39),\n",
       " ('find', 36),\n",
       " ('years', 35),\n",
       " ('city', 34),\n",
       " ('husband', 34),\n",
       " ('becomes', 33)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_f=text[text.Female == 1].reset_index()\n",
    "def remove_stop(x):\n",
    "    removed_stop=[]\n",
    "    for y in x:\n",
    "        removed_stop.append(' '.join([word for word in y.split() if word not in stop]))\n",
    "    return removed_stop\n",
    "no_stop_f=remove_stop(text_f['Summary'])\n",
    "\n",
    "su_f=str()\n",
    "for i in range(1000):\n",
    "    su_f=su_f + str(no_stop_f[i])\n",
    "\n",
    "su_f_1=preprocessing(su_f)\n",
    "\n",
    "fdist = FreqDist(su_f_1)\n",
    "print(fdist)\n",
    "fdist.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'Female',\n",
       " 'd_Female',\n",
       " 'Summary',\n",
       " 'd_Drop',\n",
       " 'vader_compound',\n",
       " 'vader_neg',\n",
       " 'vader_neu',\n",
       " 'vader_pos',\n",
       " 'Afinn',\n",
       " 'Token']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stop_f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
