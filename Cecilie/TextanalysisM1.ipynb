{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cecil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\cecil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import requests\n",
    "import nltk, nltk.sentiment, sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "name=nltk.corpus.names\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "vader=nltk.sentiment.vader.SentimentIntensityAnalyzer()\n",
    "from afinn import Afinn\n",
    "afinn = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female</th>\n",
       "      <th>d_Female</th>\n",
       "      <th>Summary</th>\n",
       "      <th>d_Drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Female  d_Female                                            Summary  d_Drop\n",
       "0     0.0       0.0  Two imprisoned men bond over a number of years...     0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2data='/Users/cecil/OneDrive/Dokumenter/sds2019_2/Group-31-SoDa/Data/movie_2.csv'\n",
    "#C:\\Users\\cecil\\OneDrive\\Dokumenter\\sds2019_2\\Group-31-SoDa\\Data\n",
    "done=pd.read_csv(path2data)\n",
    "text=done[['Female','d_Female','Summary','d_Drop']]\n",
    "text.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\cecil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "bob=text['Summary'].apply(vader.polarity_scores)\n",
    "bob_2=list(bob)\n",
    "text[[\"vader_neg\",\"vader_neu\",\"vader_pos\",\"vader_compound\"]]=pd.DataFrame(bob_2)\n",
    "text['Afinn']=text['Summary'].apply(afinn.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 26 samples and 30 outcomes>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 3),\n",
       " ('his', 2),\n",
       " ('to', 2),\n",
       " ('based', 1),\n",
       " ('on', 1),\n",
       " ('true', 1),\n",
       " ('story', 1),\n",
       " ('of', 1),\n",
       " ('jordan', 1),\n",
       " ('belfort', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "def preprocessing(string):\n",
    "    lower=string.lower()\n",
    "    token=tokenizer.tokenize(lower)\n",
    "    return token\n",
    "text['Token']=text['Summary'].apply(preprocessing)\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(text['Token'][25])\n",
    "print(fdist)\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Male Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 15516 samples and 104263 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('man', 694),\n",
       " ('young', 648),\n",
       " ('life', 633),\n",
       " ('new', 540),\n",
       " ('two', 505),\n",
       " ('in', 429),\n",
       " ('family', 419),\n",
       " ('one', 413),\n",
       " ('an', 395),\n",
       " ('world', 383),\n",
       " ('must', 369),\n",
       " ('find', 366),\n",
       " ('love', 320),\n",
       " ('when', 319),\n",
       " ('story', 312),\n",
       " ('woman', 288),\n",
       " ('finds', 274),\n",
       " ('father', 267),\n",
       " ('group', 263),\n",
       " ('he', 256),\n",
       " ('old', 255),\n",
       " ('see', 250),\n",
       " ('friends', 249),\n",
       " ('war', 247),\n",
       " ('after', 242),\n",
       " ('wife', 241),\n",
       " ('school', 239),\n",
       " ('full', 237)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "text_m=text[text.Female != 1].reset_index()\n",
    "stop=stopwords.words('english')\n",
    "\n",
    "\n",
    "stop1=stop+list(','+'a'+'.'+'\"')\n",
    "def remove_stop(x):\n",
    "    removed_stop=[]\n",
    "    for y in x:\n",
    "        removed_stop.append(' '.join([word for word in y.split() if word not in stop1]))\n",
    "    return removed_stop\n",
    "no_stop_m=remove_stop(text_m['Summary'])\n",
    "\n",
    "su_m=str()\n",
    "for i in range(6184):\n",
    "    su_m=su_m + str(no_stop_m[i])\n",
    "\n",
    "su_m_1=preprocessing(su_m)\n",
    "\n",
    "fdist = FreqDist(su_m_1)\n",
    "print(fdist)\n",
    "m = fdist.most_common(31)\n",
    "m[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (man, 694)\n",
       "1    (young, 648)\n",
       "2     (life, 633)\n",
       "3      (new, 540)\n",
       "4      (two, 505)\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List = pd.Series(m[3:])\n",
    "List.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['man', 694],\n",
       " ['young', 648],\n",
       " ['life', 633],\n",
       " ['new', 540],\n",
       " ['two', 505],\n",
       " ['in', 429],\n",
       " ['family', 419],\n",
       " ['one', 413],\n",
       " ['an', 395],\n",
       " ['world', 383],\n",
       " ['must', 369],\n",
       " ['find', 366],\n",
       " ['love', 320],\n",
       " ['when', 319],\n",
       " ['story', 312],\n",
       " ['woman', 288],\n",
       " ['finds', 274],\n",
       " ['father', 267],\n",
       " ['group', 263],\n",
       " ['he', 256],\n",
       " ['old', 255],\n",
       " ['see', 250],\n",
       " ['friends', 249],\n",
       " ['war', 247],\n",
       " ['after', 242],\n",
       " ['wife', 241],\n",
       " ['school', 239],\n",
       " ['full', 237]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List = [list(i) for i in List]\n",
    "List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stupid_words_m = [\"new\", \"in\", \"an\", \"two\", \"one\", \"when\", \"two\", \"after\", \"see\", \"find\"]\n",
    "\n",
    "for e in range(0,len(List)-len(stupid_words_m)):\n",
    "    if List[e][0] in stupid_words_m:\n",
    "        #print(List[e])\n",
    "        List.remove(List[e])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['man', 694],\n",
       " ['young', 648],\n",
       " ['life', 633],\n",
       " ['two', 505],\n",
       " ['family', 419],\n",
       " ['an', 395],\n",
       " ['world', 383],\n",
       " ['must', 369],\n",
       " ['love', 320],\n",
       " ['story', 312],\n",
       " ['woman', 288],\n",
       " ['finds', 274],\n",
       " ['father', 267],\n",
       " ['group', 263],\n",
       " ['he', 256],\n",
       " ['old', 255],\n",
       " ['friends', 249],\n",
       " ['war', 247],\n",
       " ['after', 242],\n",
       " ['wife', 241],\n",
       " ['school', 239],\n",
       " ['full', 237]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-55c6117561fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrey_color_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hsl(157,41%%, %d%%)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "stopwords = set(STOPWORDS)\n",
    "def grey_color_func(word, font_size, position,orientation,random_state=None, **kwargs):\n",
    "    return(\"hsl(157,41%%, %d%%)\" % np.random.randint(50,51))\n",
    "\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=200,\n",
    "        max_font_size=50,\n",
    "        min_font_size=5, \n",
    "        scale=5,\n",
    "        random_state=1\n",
    "    ).generate(str(data))\n",
    "    wordcloud.recolor(color_func = grey_color_func)\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "show_wordcloud(List)\n",
    "show_wordcloud(Listf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-a4db16ad0c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# Apply our color function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrouped_color_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from wordcloud import (WordCloud, get_single_color_func)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class SimpleGroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns EXACT colors\n",
    "       to certain words based on the color to words mapping\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.word_to_color = {word: color\n",
    "                              for (color, words) in color_to_words.items()\n",
    "                              for word in words}\n",
    "\n",
    "        self.default_color = default_color\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.word_to_color.get(word, self.default_color)\n",
    "    \n",
    "\n",
    "class GroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns DIFFERENT SHADES of\n",
    "       specified colors to certain words based on the color to words mapping.\n",
    "\n",
    "       Uses wordcloud.get_single_color_func\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.color_func_to_words = [\n",
    "            (get_single_color_func(color), set(words))\n",
    "            for (color, words) in color_to_words.items()]\n",
    "\n",
    "        self.default_color_func = get_single_color_func(default_color)\n",
    "\n",
    "    def get_color_func(self, word):\n",
    "        \"\"\"Returns a single_color_func associated with the word\"\"\"\n",
    "        try:\n",
    "            color_func = next(\n",
    "                color_func for (color_func, words) in self.color_func_to_words\n",
    "                if word in words)\n",
    "        except StopIteration:\n",
    "            color_func = self.default_color_func\n",
    "\n",
    "        return color_func\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.get_color_func(word)(word, **kwargs)\n",
    "\n",
    "\n",
    "color_to_words = {\n",
    "    # words below will be colored with a green single color function\n",
    "    #'#00ff00': [\"man\"],\n",
    "    # will be colored with a red single color function\n",
    "    'red': ['man']\n",
    "}\n",
    "\n",
    "# Words that are not in any of the color_to_words values\n",
    "# will be colored with a grey single color function\n",
    "default_color = 'green'\n",
    "\n",
    "# Create a color function with single tone\n",
    "# grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "\n",
    "# Create a color function with multiple tones\n",
    "grouped_color_func = GroupedColorFunc(color_to_words, default_color)\n",
    "\n",
    "# Apply our color function\n",
    "data.recolor(color_func=grouped_color_func)\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.imshow(data, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Female Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 5516 samples and 16661 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('woman', 168),\n",
       " ('young', 155),\n",
       " ('life', 122),\n",
       " ('new', 108),\n",
       " ('the', 98),\n",
       " ('girl', 90),\n",
       " ('two', 77),\n",
       " ('love', 77),\n",
       " ('one', 77),\n",
       " ('family', 69),\n",
       " ('school', 65),\n",
       " ('in', 64),\n",
       " ('finds', 62),\n",
       " ('world', 61),\n",
       " ('man', 59),\n",
       " ('mother', 59),\n",
       " ('must', 57),\n",
       " ('after', 55),\n",
       " ('an', 55),\n",
       " ('group', 54),\n",
       " ('when', 47),\n",
       " ('home', 47),\n",
       " ('town', 44),\n",
       " ('friends', 43),\n",
       " ('husband', 43),\n",
       " ('story', 43),\n",
       " ('three', 42),\n",
       " ('city', 42)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_f=text[text.Female == 1].reset_index()\n",
    "def remove_stop(x):\n",
    "    removed_stop=[]\n",
    "    for y in x:\n",
    "        removed_stop.append(' '.join([word for word in y.split() if word not in stop]))\n",
    "    return removed_stop\n",
    "no_stop_f=remove_stop(text_f['Summary'])\n",
    "\n",
    "su_f=str()\n",
    "for i in range(1000):\n",
    "    su_f=su_f + str(no_stop_f[i])\n",
    "\n",
    "su_f_1=preprocessing(su_f)\n",
    "\n",
    "fdist = FreqDist(su_f_1)\n",
    "print(fdist)\n",
    "f = fdist.most_common(30)\n",
    "f[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (woman, 168)\n",
       "1    (young, 155)\n",
       "2     (life, 122)\n",
       "3      (new, 108)\n",
       "4       (the, 98)\n",
       "dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Listf = pd.Series(f[2:])\n",
    "Listf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['woman', 168],\n",
       " ['young', 155],\n",
       " ['life', 122],\n",
       " ['new', 108],\n",
       " ['the', 98],\n",
       " ['girl', 90],\n",
       " ['two', 77],\n",
       " ['love', 77],\n",
       " ['one', 77],\n",
       " ['family', 69],\n",
       " ['school', 65],\n",
       " ['in', 64],\n",
       " ['finds', 62],\n",
       " ['world', 61],\n",
       " ['man', 59],\n",
       " ['mother', 59],\n",
       " ['must', 57],\n",
       " ['after', 55],\n",
       " ['an', 55],\n",
       " ['group', 54],\n",
       " ['when', 47],\n",
       " ['home', 47],\n",
       " ['town', 44],\n",
       " ['friends', 43],\n",
       " ['husband', 43],\n",
       " ['story', 43],\n",
       " ['three', 42],\n",
       " ['city', 42]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Listf = [list(i) for i in Listf]\n",
    "Listf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "stupid_words_f = [\"the\", \"two\", \"one\", \"in\", \"after\", \"an\", \"when\", \"three\", \"new\"]\n",
    "\n",
    "for e in range(0,len(Listf)-len(stupid_words_f)):\n",
    "    if Listf[e][0] in stupid_words_f:\n",
    "        #print(Listf[e])\n",
    "        Listf.remove(Listf[e])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['woman', 168],\n",
       " ['young', 155],\n",
       " ['life', 122],\n",
       " ['girl', 90],\n",
       " ['love', 77],\n",
       " ['family', 69],\n",
       " ['school', 65],\n",
       " ['finds', 62],\n",
       " ['world', 61],\n",
       " ['man', 59],\n",
       " ['mother', 59],\n",
       " ['must', 57],\n",
       " ['group', 54],\n",
       " ['home', 47],\n",
       " ['town', 44],\n",
       " ['friends', 43],\n",
       " ['husband', 43],\n",
       " ['story', 43],\n",
       " ['three', 42],\n",
       " ['city', 42]]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Listf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
